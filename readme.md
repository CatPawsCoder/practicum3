 Проект: Генерация текстовых отзывов с использованием нейронной сети

 Краткое описание

Цель проекта — создание нейронной сети, которая будет генерировать текстовые отзывы о различных местах (жилые комплексы, рестораны и другие объекты) на основе определенных входных параметров. Модель будет использовать такие параметры как категория места, средний рейтинг и ключевые слова для генерации отзывов, которые будут отражать общее впечатление о месте.

Данные

Для обучения использован датасет [Geo Reviews Dataset 2023](https://github.com/yandex/geo-reviews-dataset-2023), который содержит информацию о различных объектах с метками категории, рейтинга и текстовыми отзывами.

 Описание модели

Используется модель **GPT-2**, адаптированная для русскоязычных текстов (RuGPT-3 Small). Модель обучена на данных с учетом категорий, рейтингов и ключевых слов, что позволяет генерировать релевантные текстовые отзывы, учитывая различные параметры входа.

 Входные данные

Входной текст для генерации формируется в следующем формате:
df['input_text'] = "Категория: " + df['rubrics'] + " Рейтинг: " + df['rating'].astype(str) + " Место: " + df['name_ru']
 Состав команды
Единственный участник — Все задачи выполняются одним участником, включая разработку модели, обработку данных и документацию.

## Зоны ответственности

- **Разработка модели** — Создание архитектуры модели, обучение нейросети, настройка гиперпараметров.
- **Обработка данных** — Сбор, очистка и подготовка данных для тренировки модели.
- **Документация** — Написание документации и код-ревью.

**Оценка архитектуры предложенного решения, codereview**
1. Цель проекта:
Проект направлен на создание нейронной сети, способной генерировать текстовые отзывы о различных местах на основе входных параметров (категория места, средний рейтинг, ключевые слова). Это интересная задача, которая может найти широкое применение в системах рекомендаций и создания контента для сайтов.

2. Общая структура решения:
Предобработка данных: Используется токенизация данных с помощью модели, что является стандартным шагом для большинства задач обработки естественного языка (NLP). Однако важно, чтобы эта токенизация учитывала контекст и особенности языка, что может потребовать доработки.

Модель: Используется предобученная модель GPT2, которая является хорошей базой для генерации текста. Для обработки русского языка применена версия модели, основанная на GPT2 и адаптированная для русского языка, что вполне оправдано.

Обучение: Процесс обучения модели организован с использованием библиотеки transformers, что позволяет легко адаптировать модель под конкретную задачу. Однако важно учитывать, что в проекте обучение модели проводилось на достаточно ограниченном наборе данных, что может влиять на общее качество модели.

Генерация текста: Генерация текстов осуществляется с использованием методов, предоставляемых библиотекой transformers, с применением различных параметров, таких как temperature, top_k, top_p для контроля качества сгенерированного текста.

Токенизация и очистка текста: Токенизация производится с помощью GPT2 Tokenizer. После генерации текста проводится его очистка от нежелательных элементов (например, рейтингов, категорий), что делает результат более естественным.

3. Сильные стороны решения:
Использование предобученных моделей (transfer learning): Модель GPT2, адаптированная под русский язык, обеспечивает быстрый старт и сокращение времени обучения, так как использует знания, уже заложенные в предобученной модели.

Гибкость генерации текста: Параметры генерации (top_k, top_p, temperature) позволяют гибко контролировать стилистику сгенерированного текста, что важно для создания разнообразных отзывов.

Хорошая структура проекта: Использование библиотеки transformers упрощает работу с моделью и дает доступ к множеству полезных инструментов для обучения и генерации.

Отдельный этап очистки текста: Очистка сгенерированного текста от категорий, рейтингов и других нежелательных элементов демонстрирует внимание к качеству результатов.

4. Области для улучшений:
Предобработка данных: Важно гарантировать, что данные перед обучением модели прошли качественную предобработку. Это включает в себя не только токенизацию, но и возможное устранение нерелевантных данных, таких как шумовые слова, исправление орфографических ошибок и нормализация текста.

Контроль за качеством сгенерированного текста: Параметры генерации (top_k, top_p, temperature) могут быть оптимизированы для уменьшения случайных или нелепых результатов. Также стоит добавить механизмы для улучшения целостности и логичности отзывов.

Оценка качества модели: Процесс обучения модели на маленьком датасете может быть причиной того, что модель не всегда генерирует высококачественные отзывы. Для повышения качества генерации стоит подумать о увеличении объема обучающих данных и улучшении выборки.
